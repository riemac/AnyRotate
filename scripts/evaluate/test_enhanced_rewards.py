#!/usr/bin/env python3

# Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).
# All rights reserved.
#
# SPDX-License-Identifier: BSD-3-Clause

"""
æµ‹è¯•LeapHandç¯å¢ƒä¸­çš„å¢å¼ºå¥–åŠ±å‡½æ•°ï¼š
1. æ”¹è¿›çš„æ—‹è½¬é€Ÿåº¦å¥–åŠ±ï¼ˆç›®æ ‡è§’é€Ÿåº¦å‹ï¼‰
2. æŒ‡å°–è·ç¦»æƒ©ç½š
3. æ‰­çŸ©æƒ©ç½š
4. æ—‹è½¬è½´å¯¹é½å¥–åŠ±

ä½¿ç”¨æ–¹æ³•:
python scripts/evaluate/test_enhanced_rewards.py --num_envs 4 --rotation_axis_mode random

NOTE: æœ¬è„šæœ¬å¯ç”¨äºè§‚å¯Ÿæ¢ç´¢é˜¶æ®µå¥–åŠ±å‡½æ•°çš„æ•ˆæœï¼Œä»è€Œè°ƒæ•´å¥–åŠ±å‡½æ•°çš„å‚æ•°ã€‚
"""

"""Launch Isaac Sim Simulator first."""

import argparse
import sys

import torch

from isaaclab.app import AppLauncher

# æ·»åŠ å‘½ä»¤è¡Œå‚æ•°
parser = argparse.ArgumentParser(description="æµ‹è¯•LeapHandå¢å¼ºå¥–åŠ±å‡½æ•°")
parser.add_argument("--num_envs", type=int, default=4, help="ç¯å¢ƒæ•°é‡")
parser.add_argument("--rotation_axis_mode", type=str, default="random", 
                   choices=["z_axis", "x_axis", "y_axis", "random"],
                   help="æ—‹è½¬è½´æ¨¡å¼")
parser.add_argument("--headless", action="store_true", help="æ— å¤´æ¨¡å¼è¿è¡Œ")

# è§£æå‚æ•°å¹¶å¯åŠ¨åº”ç”¨
args_cli = parser.parse_args()
app_launcher = AppLauncher(args_cli)
simulation_app = app_launcher.app

import isaaclab.sim as sim_utils
from isaaclab.envs import ManagerBasedRLEnv
from isaaclab.sim import SimulationContext

# å¯¼å…¥ç¯å¢ƒé…ç½®
from leaphand.tasks.manager_based.leaphand.leaphand_continuous_rot_env_cfg import (
    LeaphandContinuousRotEnvCfg
)

def test_enhanced_rewards():
    """æµ‹è¯•å¢å¼ºå¥–åŠ±å‡½æ•°"""
    
    print("=" * 80)
    print("LeapHandè¿ç»­æ—‹è½¬ç¯å¢ƒ - å¢å¼ºå¥–åŠ±å‡½æ•°æµ‹è¯•")
    print("=" * 80)
    
    # åˆ›å»ºç¯å¢ƒé…ç½®
    env_cfg = LeaphandContinuousRotEnvCfg()
    env_cfg.scene.num_envs = args_cli.num_envs
    
    # è®¾ç½®æ—‹è½¬è½´æ¨¡å¼
    env_cfg.commands.rotation_axis.rotation_axis_mode = args_cli.rotation_axis_mode
    
    # ç¡®ä¿å¯ç”¨å¯è§†åŒ–
    env_cfg.commands.rotation_axis.debug_vis = True
    
    print(f"ç¯å¢ƒæ•°é‡: {env_cfg.scene.num_envs}")
    print(f"æ—‹è½¬è½´æ¨¡å¼: {args_cli.rotation_axis_mode}")
    print("å¢å¼ºå¥–åŠ±å‡½æ•°:")
    print("  âœ… æ—‹è½¬é€Ÿåº¦å¥–åŠ± (ç›®æ ‡è§’é€Ÿåº¦å‹)")
    print("  âœ… æŒ‡å°–è·ç¦»æƒ©ç½š")
    print("  âœ… æ‰­çŸ©æƒ©ç½š")
    print("  âœ… æ—‹è½¬è½´å¯¹é½å¥–åŠ±")
    
    # åˆ›å»ºç¯å¢ƒ
    env = ManagerBasedRLEnv(cfg=env_cfg)
    
    print("\nâœ… ç¯å¢ƒåˆ›å»ºæˆåŠŸï¼")
    print("ğŸ“Š å¥–åŠ±å‡½æ•°è¯¦æƒ…ï¼š")
    
    # æ‰“å°å¥–åŠ±ç®¡ç†å™¨ä¿¡æ¯
    reward_terms = env.reward_manager._term_names
    reward_weights = [term_cfg.weight for term_cfg in env.reward_manager._term_cfgs]
    
    for i, (name, weight) in enumerate(zip(reward_terms, reward_weights)):
        print(f"   {i+1:2d}. {name:<25} æƒé‡: {weight:+8.4f}")
    
    try:
        # é‡ç½®ç¯å¢ƒ
        env.reset()
        
        print(f"\nğŸ”„ å¼€å§‹æµ‹è¯•å¥–åŠ±å‡½æ•°...")
        
        # è¿è¡Œä»¿çœŸæ­¥éª¤
        step_count = 0
        max_steps = 500 if args_cli.headless else 1000
        
        # è®°å½•å¥–åŠ±ç»Ÿè®¡
        reward_stats = {name: [] for name in reward_terms}
        total_rewards = []
        
        while step_count < max_steps:
            # æ‰§è¡ŒéšæœºåŠ¨ä½œ
            actions = torch.randn(env.num_envs, env.action_manager.total_action_dim, device=env.device)
            actions = torch.clamp(actions, -1.0, 1.0)
            
            # æ‰§è¡Œæ­¥éª¤
            obs, rewards, terminated, truncated, info = env.step(actions)
            step_count += 1
            
            # è®°å½•å¥–åŠ±ç»Ÿè®¡
            total_rewards.append(rewards.mean().item())
            
            # è®°å½•å„é¡¹å¥–åŠ±
            if hasattr(env.reward_manager, '_step_reward'):
                for i, name in enumerate(reward_terms):
                    reward_value = env.reward_manager._step_reward[:, i].mean().item()
                    reward_stats[name].append(reward_value)
            
            # æ¯100æ­¥æ‰“å°ä¸€æ¬¡ç»Ÿè®¡ä¿¡æ¯
            if step_count % 100 == 0:
                print(f"\nğŸ“ˆ æ­¥éª¤ {step_count:4d}/{max_steps}:")
                print(f"   æ€»å¥–åŠ±: {rewards.mean().item():+8.4f}")
                
                # æ‰“å°å„é¡¹å¥–åŠ±çš„å½“å‰å€¼
                if hasattr(env.reward_manager, '_step_reward'):
                    for i, name in enumerate(reward_terms):
                        current_reward = env.reward_manager._step_reward[:, i].mean().item()
                        print(f"   {name:<25}: {current_reward:+8.4f}")
        
        print(f"\nâœ… æµ‹è¯•å®Œæˆï¼å…±è¿è¡Œ {step_count} æ­¥")
        
        # è®¡ç®—å¹¶æ˜¾ç¤ºå¥–åŠ±ç»Ÿè®¡
        if reward_stats:
            print("\nğŸ“Š å¥–åŠ±ç»Ÿè®¡æ‘˜è¦:")
            print(f"   æ€»å¥–åŠ±å¹³å‡å€¼: {sum(total_rewards)/len(total_rewards):+8.4f}")
            print(f"\n   {'å¥–åŠ±é¡¹':<25} {'æƒé‡':<8} {'å¹³å‡å€¼':<10} {'èŒƒå›´'}")
            print(f"   {'-'*25} {'-'*8} {'-'*10} {'-'*25}")
            
            for i, name in enumerate(reward_terms):
                if reward_stats[name]:
                    weight = reward_weights[i]
                    avg_reward = sum(reward_stats[name]) / len(reward_stats[name])
                    min_reward = min(reward_stats[name])
                    max_reward = max(reward_stats[name])
                    print(f"   {name:<25} {weight:+7.1f} {avg_reward:+9.4f} [{min_reward:+7.4f}, {max_reward:+7.4f}]")
        
        if not args_cli.headless:
            print("\nâ¸ï¸  æµ‹è¯•å·²å®Œæˆï¼Œä½†ç¯å¢ƒä»åœ¨è¿è¡Œ")
            print("   ğŸ’¡ æ‚¨å¯ä»¥ç»§ç»­åœ¨Isaac Simä¸­è§‚å¯Ÿå¯è§†åŒ–æ•ˆæœ")
            print("   ğŸ’¡ æŒ‰Ctrl+Cé€€å‡ºç¨‹åº")
            
            # ä¿æŒç¯å¢ƒè¿è¡Œï¼Œè®©ç”¨æˆ·è§‚å¯Ÿ
            try:
                while True:
                    actions = torch.randn(env.num_envs, env.action_manager.total_action_dim, device=env.device)
                    actions = torch.clamp(actions, -0.3, 0.3)  # ä½¿ç”¨è¾ƒå°çš„åŠ¨ä½œå¹…åº¦
                    env.step(actions)
            except KeyboardInterrupt:
                print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨é€€å‡º...")
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # å…³é—­ç¯å¢ƒ
        env.close()
        print("\nâœ… ç¯å¢ƒå·²å…³é—­ï¼")

def main():
    """ä¸»å‡½æ•°"""
    try:
        test_enhanced_rewards()
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return 1
    return 0

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    exit_code = main()
    # å…³é—­ä»¿çœŸåº”ç”¨
    simulation_app.close()
    sys.exit(exit_code)
